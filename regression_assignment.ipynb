{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8cc7fa-c47d-45a5-8a25-7ce1d48733e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Absolutely! Here's the **Linear and Polynomial Regression Q&A** with **clean, sequential question numbers** for easy reference:\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŸ¦ **Simple Linear Regression**\n",
    "\n",
    "**Q1. What is Simple Linear Regression?**  \n",
    "A statistical method to model the relationship between a dependent variable (Y) and one independent variable (X) using the equation `Y = mX + c`.\n",
    "\n",
    "**Q2. What are the key assumptions of Simple Linear Regression?**  \n",
    "1. Linearity  \n",
    "2. Independence  \n",
    "3. Homoscedasticity  \n",
    "4. Normality of residuals  \n",
    "5. No multicollinearity (not applicable with one predictor)\n",
    "\n",
    "**Q3. What does the coefficient m represent in the equation Y = mX + c?**  \n",
    "It represents the change in Y for a one-unit change in X.\n",
    "\n",
    "**Q4. What does the intercept c represent in the equation Y = mX + c?**  \n",
    "The predicted value of Y when X = 0.\n",
    "\n",
    "**Q5. How do we calculate the slope m in Simple Linear Regression?**  \n",
    "\\[\n",
    "m = \\frac{n(SUM XY) - (SUM X)(SUM Y)}{n(SUM X^2) - (SUM X)^2}\n",
    "\\]\n",
    "\n",
    "**Q6. What is the purpose of the least squares method in Simple Linear Regression?**  \n",
    "To minimize the sum of squared differences between actual and predicted Y values.\n",
    "\n",
    "**Q7. How is the coefficient of determination (RÂ²) interpreted in Simple Linear Regression?**  \n",
    "RÂ² represents the proportion of variance in Y explained by X, ranging from 0 to 1.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŸ¨ **Multiple Linear Regression**\n",
    "\n",
    "**Q8. What is Multiple Linear Regression?**  \n",
    "An extension of simple linear regression that models Y using two or more independent variables.\n",
    "\n",
    "**Q9. What is the main difference between Simple and Multiple Linear Regression?**  \n",
    "Simple regression has one independent variable; multiple has two or more.\n",
    "\n",
    "**Q10. What are the key assumptions of Multiple Linear Regression?**  \n",
    "Same as simple regression, plus:  \n",
    "- No perfect multicollinearity  \n",
    "- No autocorrelation of residuals\n",
    "\n",
    "**Q11. What is heteroscedasticity, and how does it affect regression results?**  \n",
    "Unequal variance of residuals. It leads to inefficient estimates and unreliable hypothesis testing.\n",
    "\n",
    "**Q12. How can you improve a Multiple Linear Regression model with high multicollinearity?**  \n",
    "- Remove or combine correlated predictors  \n",
    "- Use PCA  \n",
    "- Apply Ridge or Lasso regression\n",
    "\n",
    "**Q13. What are common techniques for transforming categorical variables in regression models?**  \n",
    "- One-hot encoding  \n",
    "- Label encoding  \n",
    "- Target encoding\n",
    "\n",
    "**Q14. What is the role of interaction terms in Multiple Linear Regression?**  \n",
    "They capture the combined effect of two or more predictors on the response variable.\n",
    "\n",
    "**Q15. How can the interpretation of intercept differ between Simple and Multiple Regression?**  \n",
    "Simple: Y when X = 0  \n",
    "Multiple: Y when all predictors = 0 (may not be meaningful)\n",
    "\n",
    "**Q16. What is the significance of the slope in regression, and how does it affect predictions?**  \n",
    "The slope shows how much the dependent variable changes per unit change in the predictor.\n",
    "\n",
    "**Q17. How does the intercept provide context for variable relationships?**  \n",
    "It's the predicted value of Y when all predictors are zero; serves as a baseline.\n",
    "\n",
    "**Q18. What are the limitations of using RÂ² alone as a performance metric?**  \n",
    "- Always increases with more variables  \n",
    "- Doesn't reflect model complexity  \n",
    "- Use Adjusted RÂ² instead\n",
    "\n",
    "**Q19. How would you interpret a large standard error for a regression coefficient?**  \n",
    "Indicates that the coefficient estimate is not reliableâ€”could be due to noise or multicollinearity.\n",
    "\n",
    "**Q20. How can heteroscedasticity be identified in residual plots, and why address it?**  \n",
    "Residuals form a fan shape or pattern. Violates assumptions; can affect inference.\n",
    "\n",
    "**Q21. What does it mean if RÂ² is high but Adjusted RÂ² is low?**  \n",
    "Model may be overfitted with irrelevant predictors.\n",
    "\n",
    "**Q22. Why is it important to scale variables in Multiple Linear Regression?**  \n",
    "Scaling ensures equal contribution, especially important for regularization methods (like Ridge/Lasso).\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŸ© **Polynomial Regression**\n",
    "\n",
    "**Q23. What is polynomial regression?**  \n",
    "A regression model where the relationship is expressed as a polynomial equation.\n",
    "\n",
    "**Q24. How does polynomial regression differ from linear regression?**  \n",
    "Polynomial regression fits curves, while linear fits straight lines.\n",
    "\n",
    "**Q25. When is polynomial regression used?**  \n",
    "When data shows a non-linear relationship between X and Y.\n",
    "\n",
    "**Q26. What is the general equation for polynomial regression?**  \n",
    "\\[\n",
    "Y = a + b1X + b2X^2 + ... + bnX^n\n",
    "\\]\n",
    "\n",
    "**Q27. Can polynomial regression be applied to multiple variables?**  \n",
    "Yes, by including polynomial terms for each predictor variable.\n",
    "\n",
    "**Q28. What are the limitations of polynomial regression?**  \n",
    "- Prone to overfitting  \n",
    "- Less interpretable  \n",
    "- Poor extrapolation outside data range\n",
    "\n",
    "**Q29. How to select the degree of a polynomial model?**  \n",
    "Use cross-validation, adjusted RÂ², AIC, or BIC for best fit.\n",
    "\n",
    "**Q30. Why is visualization important in polynomial regression?**  \n",
    "Helps detect overfitting, assess fit, and communicate non-linear trends.\n",
    "\n",
    "**Q31. How is polynomial regression implemented in Python?**  \n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you want these grouped into flashcards, exported to Notion, or formatted as quiz questions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

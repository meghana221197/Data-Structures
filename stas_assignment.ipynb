{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0f723-6b14-4552-aef2-6f8650b8b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "### 1. **What is statistics, and why is it important?**\n",
    "   - **Statistics** is the study of collecting, analyzing, interpreting, presenting, and organizing data. It is important because it helps individuals and organizations make informed decisions based on data rather than assumptions, enabling evidence-based actions.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5468f173-005e-41a4-b11d-c2e2832b0868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### 2. **What are the two main types of statistics?**\\n   - **Descriptive statistics**: Summarizes or describes the characteristics of a data set.\\n   - **Inferential statistics**: Makes predictions or inferences about a population based on a sample of data.\\n   '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "### 2. **What are the two main types of statistics?**\n",
    "   - **Descriptive statistics**: Summarizes or describes the characteristics of a data set.\n",
    "   - **Inferential statistics**: Makes predictions or inferences about a population based on a sample of data.\n",
    "   \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d7911-c4b5-4455-b064-18091268b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 3. **What are descriptive statistics?**\n",
    "   - Descriptive statistics refers to the methods used to summarize and present data in a meaningful way, such as through measures like the mean, median, mode, and graphical representations (e.g., histograms).\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a120074-1b44-4a79-a33d-9d7e816e3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### 4. **What is inferential statistics?**\n",
    "   - Inferential statistics involves drawing conclusions or making predictions about a population based on a sample of data. It includes hypothesis testing, confidence intervals, and regression analysis.\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45307e10-8752-46dc-9ce4-1ec8bfdf1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. What is sampling in statistics?\n",
    "Sampling is the process of selecting a subset (sample) from a larger population for the purpose of estimating characteristics of the entire population.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31a132-2fda-49da-8166-71abc9620ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 6. **What are the different types of sampling methods?**\n",
    "   - **Simple random sampling**: Every individual has an equal chance of being selected.\n",
    "   - **Systematic sampling**: Every nth member is selected from a list.\n",
    "   - **Stratified sampling**: Population is divided into subgroups (strata) and samples are taken from each group.\n",
    "   - **Cluster sampling**: The population is divided into clusters, and some clusters are randomly selected for sampling.\n",
    "   - **Convenience sampling**: Sampling based on ease of access.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7db66e-7828-4cc9-adeb-66f1dea087f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 7. **What is the difference between random and non-random sampling?**\n",
    "   - **Random sampling**: Every member of the population has an equal chance of being selected.\n",
    "   - **Non-random sampling**: Selection is based on convenience or subjective judgment, and not all members have an equal chance of being chosen.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ec52c-f55c-4379-bded-19b858e2ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 8. **Define and give examples of qualitative and quantitative data.**\n",
    "   - **Qualitative data**: Non-numeric data that can be categorized (e.g., colors, gender, types of animals).\n",
    "   - **Quantitative data**: Numeric data that can be measured or counted (e.g., height, age, income).\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7737fed-96d6-4ca8-9073-40764bd96f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 9. **What are the different types of data in statistics?**\n",
    "   - **Nominal data**: Categories without any order (e.g., gender, race).\n",
    "   - **Ordinal data**: Categories with a meaningful order but no fixed interval (e.g., ranks, education level).\n",
    "   - **Interval data**: Numeric data with equal intervals but no true zero point (e.g., temperature in Celsius).\n",
    "   - **Ratio data**: Numeric data with a true zero point, allowing for meaningful ratios (e.g., height, weight, income).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a31bef-12f7-4c6f-8f0f-8338026dd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 10. **Explain nominal, ordinal, interval, and ratio levels of measurement.**\n",
    "   - **Nominal**: Categories without order (e.g., eye color).\n",
    "   - **Ordinal**: Categories with a specific order (e.g., survey rankings).\n",
    "   - **Interval**: Ordered data with equal intervals but no absolute zero (e.g., temperature).\n",
    "   - **Ratio**: Ordered data with equal intervals and an absolute zero (e.g., age, salary).\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e3d8d-f476-403c-999e-b3807393fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 11. **What is the measure of central tendency?**\n",
    "   - Measures of central tendency describe the center of a data set. The main measures are the **mean**, **median**, and **mode**.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad234a8f-4505-47f6-ae48-f4db114c23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 12. **Define mean, median, and mode.**\n",
    "   - **Mean**: The average of all data points.\n",
    "   - **Median**: The middle value when data is arranged in order.\n",
    "   - **Mode**: The value that appears most frequently in a data set.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6feea70-7b44-4e12-a044-43f8867e1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 13. **What is the significance of the measure of central tendency?**\n",
    "   - Measures of central tendency provide a single value that represents the \"center\" or typical value of a data set, helping to summarize data for easy comparison.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4417786-8632-4e1c-88e2-a016706ba564",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### 14. **What is variance, and how is it calculated?**\n",
    "   - **Variance** is the measure of the spread of a data set. It is calculated as the average of the squared differences from the mean.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8fe82-648e-42dc-bb02-515ce5fa8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 15. **What is standard deviation, and why is it important?**\n",
    "   - **Standard deviation** measures the average distance of each data point from the mean. It is important because it provides insight into the variability or spread of the data. A low standard deviation means data points are close to the mean, while a high standard deviation indicates more spread.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dddd89-2644-4f95-b2b4-d87f2b38d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 16. **Define and explain the term range in statistics.**\n",
    "   - **Range** is the difference between the maximum and minimum values in a data set. It provides a simple measure of the spread of data.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba07fc-f01a-4049-b390-aa2753ebdf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 17. **What is the difference between variance and standard deviation?**\n",
    "   - Both measure the spread of data, but **variance** is the average of squared differences from the mean, while **standard deviation** is the square root of variance. Standard deviation is often easier to interpret because it is in the same units as the data.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f275a-529f-4c22-8e95-3e247b2d4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 18. **What is skewness in a dataset?**\n",
    "   - **Skewness** refers to the asymmetry of the data distribution. If the data leans to the left or right, it is said to be skewed.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da4c6f-8a13-49f3-bbe6-688379166fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 19. **What does it mean if a dataset is positively or negatively skewed?**\n",
    "   - **Positively skewed**: The right tail (larger values) is longer or fatter than the left.\n",
    "   - **Negatively skewed**: The left tail (smaller values) is longer or fatter than the right.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d228a-dd9f-454b-afee-d00151dc8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 20. **Define and explain kurtosis.**\n",
    "   - **Kurtosis** measures the \"tailedness\" of a data distribution. High kurtosis means more extreme values (outliers) than a normal distribution, while low kurtosis suggests fewer outliers.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef73820-fb5c-4438-bfe1-120fa8021d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 21. **What is the purpose of covariance?**\n",
    "   - **Covariance** measures how two variables change together. A positive covariance indicates that as one variable increases, the other tends to increase, while a negative covariance suggests that one variable increases as the other decreases.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070291e5-4643-4909-a379-935452708fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### 22. **What does correlation measure in statistics?**\n",
    "   - **Correlation** quantifies the strength and direction of the relationship between two variables. It ranges from -1 (perfect negative correlation) to 1 (perfect positive correlation), with 0 indicating no relationship.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be46a3-3b6d-4076-b8a3-9afa22ab5287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### 23. **What is the difference between covariance and correlation?**\n",
    "   - **Covariance** provides a measure of the direction of the relationship between variables but is not standardized, making it difficult to interpret. **Correlation** is a standardized version of covariance, which makes it easier to compare the strength and direction of relationships between different pairs of variables.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52140d0-f025-481f-80da-41b1b18934e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 24. **What are some real-world applications of statistics?**\n",
    "   - **Healthcare**: Analyzing patient data to improve treatment and predict disease outcomes.\n",
    "   - **Business**: Making decisions based on customer surveys, market trends, and sales data.\n",
    "   - **Sports**: Using player statistics to analyze performance and predict outcomes.\n",
    "   - **Social sciences**: Studying behaviors, social trends, and public opinion.\n",
    "   - **Government**: Policy decisions based on demographic and economic data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39d898c-9687-477c-a637-542a646ae80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### 1. **How do you calculate the mean, median, and mode of a dataset?**\\n   - **Mean**: Add all the values and divide by the number of values.\\n   - **Median**: The middle value when data is arranged in ascending order.\\n   - **Mode**: The value that appears most frequently in the dataset.\\n\\n\\nimport statistics\\n\\ndata = [12, 15, 14, 10, 15, 13, 12, 14]\\n\\nmean = statistics.mean(data)\\nmedian = statistics.median(data)\\nmode = statistics.mode(data)\\n\\nprint(f\"Mean: {mean}, Median: {median}, Mode: {mode}\")\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "### 1. **How do you calculate the mean, median, and mode of a dataset?**\n",
    "   - **Mean**: Add all the values and divide by the number of values.\n",
    "   - **Median**: The middle value when data is arranged in ascending order.\n",
    "   - **Mode**: The value that appears most frequently in the dataset.\n",
    "\n",
    "\n",
    "import statistics\n",
    "\n",
    "data = [12, 15, 14, 10, 15, 13, 12, 14]\n",
    "\n",
    "mean = statistics.mean(data)\n",
    "median = statistics.median(data)\n",
    "mode = statistics.mode(data)\n",
    "\n",
    "print(f\"Mean: {mean}, Median: {median}, Mode: {mode}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec0e8b-7879-4a65-adc6-b32d8e072e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 2. **Write a Python program to compute the variance and standard deviation of a dataset.**\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = [12, 15, 14, 10, 15, 13, 12, 14]\n",
    "\n",
    "variance = np.var(data)\n",
    "std_dev = np.std(data)\n",
    "\n",
    "print(f\"Variance: {variance}, Standard Deviation: {std_dev}\")\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0356949a-dbdb-4094-a8cf-4b2c92ca2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 3. **Create a dataset and classify it into nominal, ordinal, interval, and ratio types.**\n",
    "\n",
    "\n",
    "nominal_data = [\"Red\", \"Green\", \"Blue\", \"Green\"]  # No inherent order\n",
    "ordinal_data = [\"Low\", \"Medium\", \"High\"]  # Ordered categories\n",
    "interval_data = [30, 25, 20, 35]  # No true zero (temperature in Celsius)\n",
    "ratio_data = [5, 10, 15, 20]  # True zero exists (height or weight)\n",
    "\n",
    "print(f\"Nominal: {nominal_data}, Ordinal: {ordinal_data}, Interval: {interval_data}, Ratio: {ratio_data}\")\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a618b-e825-4536-af3e-e334e2a9b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 4. **Implement sampling techniques like random sampling and stratified sampling.**\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Age': [23, 45, 12, 36, 50, 33, 18, 60, 20, 29],\n",
    "    'Income': [30000, 50000, 12000, 45000, 60000, 33000, 18000, 70000, 25000, 32000]\n",
    "})\n",
    "\n",
    "# Random Sampling\n",
    "random_sample = data.sample(n=5, random_state=1)\n",
    "print(f\"Random Sampling:\\n{random_sample}\")\n",
    "\n",
    "# Stratified Sampling (based on 'Age' for example)\n",
    "# Creating age categories\n",
    "data['Age_Group'] = pd.cut(data['Age'], bins=[0, 20, 40, 60], labels=[\"0-20\", \"21-40\", \"41-60\"])\n",
    "stratified_sample = data.groupby('Age_Group', group_keys=False).apply(lambda x: x.sample(int(0.3 * len(x))))\n",
    "print(f\"Stratified Sampling:\\n{stratified_sample}\")\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e0fc9-536a-4320-960b-3acaf38dbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 5. **Write a Python function to calculate the range of a dataset.**\n",
    "\n",
    "\n",
    "def calculate_range(data):\n",
    "    return max(data) - min(data)\n",
    "\n",
    "data = [12, 15, 14, 10, 15, 13, 12, 14]\n",
    "range_value = calculate_range(data)\n",
    "print(f\"Range: {range_value}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683bad36-38bf-467f-b818-3223878de479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 6. **Create a dataset and plot its histogram to visualize skewness.**\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.normal(0, 1, 1000)  # Normally distributed data\n",
    "\n",
    "plt.hist(data, bins=30, edgecolor='black')\n",
    "plt.title(\"Histogram to Visualize Skewness\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452b4dc-a640-4d69-be32-b9deaad76f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 7. **Calculate skewness and kurtosis of a dataset using Python libraries.**\n",
    "\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "data = [12, 15, 14, 10, 15, 13, 12, 14]\n",
    "\n",
    "skewness = skew(data)\n",
    "kurt = kurtosis(data)\n",
    "\n",
    "print(f\"Skewness: {skewness}, Kurtosis: {kurt}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50449a-443f-4653-a5b9-0b65a4e2839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 8. **Generate a dataset and demonstrate positive and negative skewness.**\n",
    "\n",
    "\n",
    "# Positive Skew\n",
    "positive_skew_data = np.random.exponential(1, 1000)\n",
    "plt.hist(positive_skew_data, bins=30, edgecolor='black')\n",
    "plt.title(\"Positive Skew\")\n",
    "plt.show()\n",
    "\n",
    "# Negative Skew\n",
    "negative_skew_data = -np.random.exponential(1, 1000)\n",
    "plt.hist(negative_skew_data, bins=30, edgecolor='black')\n",
    "plt.title(\"Negative Skew\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6981c0c-424c-4a1b-970d-09060d915cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 9. **Write a Python script to calculate covariance between two datasets.**\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data1 = [12, 15, 14, 10, 15, 13, 12, 14]\n",
    "data2 = [9, 11, 10, 6, 12, 7, 8, 10]\n",
    "\n",
    "covariance = np.cov(data1, data2)[0, 1]\n",
    "print(f\"Covariance: {covariance}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3763a1be-5c41-4f64-9e87-0ef34fa4b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 10. **Write a Python script to calculate the correlation coefficient between two datasets.**\n",
    "\n",
    "\n",
    "correlation = np.corrcoef(data1, data2)[0, 1]\n",
    "print(f\"Correlation Coefficient: {correlation}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6f125-bbf4-4857-8d01-d3e457e9a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 11. **Create a scatter plot to visualize the relationship between two variables.**\n",
    "\n",
    "\n",
    "plt.scatter(data1, data2)\n",
    "plt.title(\"Scatter Plot of Data1 vs Data2\")\n",
    "plt.xlabel(\"Data1\")\n",
    "plt.ylabel(\"Data2\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc52b51-15d6-41a4-aa71-0677e04efd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### 12. **Implement and compare simple random sampling and systematic sampling.**\n",
    "\n",
    "\n",
    "# Simple Random Sampling\n",
    "random_sample = np.random.choice(data, size=3, replace=False)\n",
    "\n",
    "# Systematic Sampling (taking every 3rd element)\n",
    "systematic_sample = data[::3]\n",
    "\n",
    "print(f\"Random Sampling: {random_sample}\")\n",
    "print(f\"Systematic Sampling: {systematic_sample}\")\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4815fc2-a07b-4add-9c7e-63050c5f419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 13. **Calculate the mean, median, and mode of grouped data.**\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Grouped data\n",
    "grouped_data = pd.DataFrame({\n",
    "    'Class': ['0-10', '11-20', '21-30', '31-40'],\n",
    "    'Frequency': [5, 10, 8, 12]\n",
    "})\n",
    "\n",
    "# Midpoint of each class\n",
    "grouped_data['Midpoint'] = [5, 15, 25, 35]\n",
    "\n",
    "# Mean of grouped data\n",
    "mean = np.average(grouped_data['Midpoint'], weights=grouped_data['Frequency'])\n",
    "print(f\"Mean: {mean}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc0c7b-5d25-40ac-ae74-c9578d007bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 14. **Simulate data using Python and calculate its central tendency and dispersion.**\n",
    "\n",
    "\n",
    "simulated_data = np.random.normal(loc=50, scale=10, size=1000)\n",
    "\n",
    "mean_simulated = np.mean(simulated_data)\n",
    "std_dev_simulated = np.std(simulated_data)\n",
    "\n",
    "print(f\"Simulated Data Mean: {mean_simulated}, Standard Deviation: {std_dev_simulated}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ae967-b54d-4bf7-b4e3-6a422d6dd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### 15. **Use NumPy or pandas to summarize a datasetâ€™s descriptive statistics.**\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Age': [23, 45, 12, 36, 50, 33, 18, 60, 20, 29],\n",
    "    'Income': [30000, 50000, 12000, 45000, 60000, 33000, 18000, 70000, 25000, 32000]\n",
    "})\n",
    "\n",
    "# Descriptive statistics\n",
    "print(df.describe())\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159107ef-c548-4ce0-816b-ce9a7e13af1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3367057328.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "### 16. **Plot a boxplot to understand the spread and identify outliers.**\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(data=df['Income'])\n",
    "plt.title(\"Boxplot of Income\")\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d336a-2fab-427e-acfe-f89eaff7edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 17. **Calculate the interquartile range (IQR) of a dataset.**\n",
    "\n",
    "\n",
    "Q1 = np.percentile(data, 25)\n",
    "Q3 = np.percentile(data, 75)\n",
    "IQR = Q3 - Q1\n",
    "print(f\"IQR: {IQR}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c567ad-53a1-4c6e-a0e8-cf5bf392f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### 18. **Implement Z-score normalization and explain its significance.**\n",
    "\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_scores = zscore(data)\n",
    "print(f\"Z-scores: {z_scores}\")\n",
    "\n",
    "\n",
    "Z-score normalization helps standardize the data, making it easier to compare datasets with different units or scales.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40148cb7-0850-4096-b2fd-06aabdbb7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 19. **Compare two datasets using their standard deviations.**\n",
    "\n",
    "\n",
    "std_dev1 = np.std(data1)\n",
    "std_dev2 = np.std(data2)\n",
    "\n",
    "print(f\"Standard Deviation of Data1: {std_dev1}, Data2: {std_dev2}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d445b28-54c2-4db8-9d5a-9258687be3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 20. **Write a Python program to visualize covariance using a heatmap.**\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "cov_matrix = np.cov(data1, data2)\n",
    "sns.heatmap(cov_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Covariance Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b42883-b5fd-4eaf-98ed-f19ca9c4a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### 21. **Use seaborn to create a correlation matrix for a dataset.**\n",
    "\n",
    "\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff9f63-53e7-434e-80a7-09074e5bc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### 22. **Generate a dataset and implement both variance and standard deviation computations.**\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "dataset = np.random.randint(1, 100, 50)\n",
    "\n",
    "variance = np.var(dataset)\n",
    "std_dev = np.std(dataset)\n",
    "\n",
    "print(f\"Variance: {variance}, Standard Deviation: {std_dev}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d963be-59dc-4080-8638-b222698d7701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "### 23. **Visualize skewness and kurtosis using Python libraries like matplotlib or seaborn.**\n",
    "\n",
    "\n",
    "sns.distplot(dataset, kde=True, bins=10)\n",
    "plt.title(\"Distribution with Skewness and Kurtosis\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f34a557-f3e4-479c-b896-1f0c7ac65c09",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3495286449.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "### 24. **Implement the Pearson and Spearman correlation coefficients for a dataset.**\n",
    "\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "pearson_corr, _ = pearsonr(data1, data2)\n",
    "spearman_corr, _ = spearmanr(data1, data2)\n",
    "\n",
    "print(f\"Pearson Correlation: {pearson_corr}, Spearman Correlation: {spearman_corr}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4c84a-d2d9-40b5-9e6a-4f044bd42cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b6b08-7df3-4635-adff-3d55bc648cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

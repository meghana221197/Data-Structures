{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDwKL5hNfzcl"
      },
      "outputs": [],
      "source": [
        "Sure! Here's a numbered list with answers to the questions you mentioned:\n",
        "\n",
        "---\n",
        "\n",
        "### **1) What is hypothesis testing in statistics?**\n",
        "Hypothesis testing is a statistical method used to make inferences or draw conclusions about a population based on sample data. It involves two competing hypotheses:\n",
        "- **Null Hypothesis (H₀)**: Assumes no effect or no difference exists in the population.\n",
        "- **Alternative Hypothesis (H₁)**: Suggests that there is an effect or a difference.\n",
        "\n",
        "The goal is to determine whether the sample data provides sufficient evidence to reject the null hypothesis.\n",
        "\n",
        "### **2) What is the null hypothesis, and how does it differ from the alternative hypothesis?**\n",
        "- **Null Hypothesis (H₀)**: Assumes no effect or no relationship. It is the hypothesis that is tested for rejection.\n",
        "  - Example: \"There is no difference between two groups.\"\n",
        "- **Alternative Hypothesis (H₁ or Ha)**: The hypothesis that there is a significant effect or relationship.\n",
        "  - Example: \"There is a difference between two groups.\"\n",
        "\n",
        "### **3) What is the significance level in hypothesis testing, and why is it important?**\n",
        "The **significance level (α)** is the threshold used to determine whether to reject the null hypothesis. It defines the probability of making a **Type I error** (i.e., rejecting a true null hypothesis). A common significance level is 0.05 (5%).\n",
        "- **Importance**: It controls the risk of falsely rejecting the null hypothesis. Smaller α reduces Type I error.\n",
        "\n",
        "### **4) What does a P-value represent in hypothesis testing?**\n",
        "The **P-value** is the probability of observing results as extreme as those in the sample, assuming the null hypothesis is true. A smaller P-value indicates stronger evidence against the null hypothesis.\n",
        "\n",
        "### **5) How do you interpret the P-value in hypothesis testing?**\n",
        "- **P-value < α**: Reject the null hypothesis (indicates sufficient evidence for the alternative hypothesis).\n",
        "- **P-value ≥ α**: Fail to reject the null hypothesis (insufficient evidence for the alternative hypothesis).\n",
        "\n",
        "### **6) What are Type 1 and Type 2 errors in hypothesis testing?**\n",
        "- **Type I Error (False Positive)**: Rejecting the null hypothesis when it is actually true.\n",
        "- **Type II Error (False Negative)**: Failing to reject the null hypothesis when it is actually false.\n",
        "\n",
        "### **7) What is the difference between a one-tailed and a two-tailed test in hypothesis testing?**\n",
        "- **One-Tailed Test**: The alternative hypothesis is directional (testing if a parameter is greater than or less than a certain value).\n",
        "- **Two-Tailed Test**: The alternative hypothesis is non-directional (testing if a parameter is different from a certain value, either greater or smaller).\n",
        "\n",
        "### **8) What is the Z-test, and when is it used in hypothesis testing?**\n",
        "The **Z-test** is used to compare the sample mean to the population mean when the sample size is large (typically n > 30) or when the population standard deviation is known.\n",
        "\n",
        "### **9) How do you calculate the Z-score, and what does it represent in hypothesis testing?**\n",
        "The **Z-score** is calculated as:\n",
        "\\[ Z = \\frac{X - \\mu}{\\sigma / \\sqrt{n}} \\]\n",
        "- \\(X\\) = sample mean, \\( \\mu \\) = population mean, \\( \\sigma \\) = population standard deviation, \\( n \\) = sample size.\n",
        "- **Interpretation**: It represents the number of standard deviations the sample mean is from the population mean.\n",
        "\n",
        "### **10) What is the T-distribution, and when should it be used instead of the normal distribution?**\n",
        "The **T-distribution** is used when the sample size is small (typically n < 30) or the population standard deviation is unknown. It has heavier tails and is more spread out than the normal distribution.\n",
        "- **When to use**: When the population standard deviation is unknown or the sample size is small.\n",
        "\n",
        "### **11) What is the difference between a Z-test and a T-test?**\n",
        "- **Z-test**: Used for large samples (n > 30) or when the population standard deviation is known.\n",
        "- **T-test**: Used for small samples (n < 30) or when the population standard deviation is unknown.\n",
        "\n",
        "### **12) What is the T-test, and how is it used in hypothesis testing?**\n",
        "The **T-test** is used to determine if there is a significant difference between the means of two groups (for small sample sizes or unknown population standard deviation).\n",
        "- **Types**:\n",
        "  - **One-sample T-test**: Compares a sample mean to a known value.\n",
        "  - **Independent T-test**: Compares the means of two independent groups.\n",
        "  - **Paired T-test**: Compares means from the same group at different times or conditions.\n",
        "\n",
        "### **13) What is the relationship between Z-test and T-test in hypothesis testing?**\n",
        "Both tests are used to compare sample means to population parameters. The difference is that:\n",
        "- **Z-test** uses the normal distribution and is used for large samples or known population standard deviations.\n",
        "- **T-test** uses the T-distribution and is used for small samples or unknown population standard deviations.\n",
        "\n",
        "### **14) What is a confidence interval, and how is it used to interpret statistical results?**\n",
        "A **confidence interval (CI)** is a range of values that estimates the true population parameter with a specified level of confidence (e.g., 95%).\n",
        "- **Interpretation**: A 95% CI means that we are 95% confident that the true parameter lies within this interval.\n",
        "\n",
        "### **15) What is the margin of error, and how does it affect the confidence interval?**\n",
        "The **margin of error** is the range of values added and subtracted from the sample statistic to create the confidence interval. It is influenced by sample size and variability.\n",
        "- **Effect**: Larger margins of error result in wider confidence intervals, indicating more uncertainty.\n",
        "\n",
        "### **16) How is Bayes' Theorem used in statistics, and what is its significance?**\n",
        "**Bayes' Theorem** updates the probability of a hypothesis based on new evidence. It combines prior knowledge (prior probability) and observed data (likelihood) to calculate the posterior probability.\n",
        "- **Significance**: It provides a framework for incorporating new information into probabilistic models.\n",
        "\n",
        "### **17) What is the Chi-square distribution, and when is it used?**\n",
        "The **Chi-square distribution** is a probability distribution used for categorical data. It is applied in tests like the **Chi-square goodness of fit test** and the **Chi-square test for independence**.\n",
        "\n",
        "### **18) What is the Chi-square goodness of fit test, and how is it applied?**\n",
        "The **Chi-square goodness of fit test** compares observed frequencies to expected frequencies to see if a sample follows a hypothesized distribution.\n",
        "- **Application**: It is used to test whether categorical data follows a specific distribution.\n",
        "\n",
        "### **19) What is the F-distribution, and when is it used in hypothesis testing?**\n",
        "The **F-distribution** is used to test the variances of two or more populations. It is commonly applied in **ANOVA** and regression analysis to compare variances.\n",
        "\n",
        "### **20) What is an ANOVA test, and what are its assumptions?**\n",
        "**ANOVA (Analysis of Variance)** compares means of three or more groups to determine if at least one differs significantly.\n",
        "- **Assumptions**:\n",
        "  - Data is normally distributed.\n",
        "  - Samples are independent.\n",
        "  - Homogeneity of variance (equal variances).\n",
        "\n",
        "### **21) What are the different types of ANOVA tests?**\n",
        "- **One-Way ANOVA**: Compares means across multiple groups based on a single factor.\n",
        "- **Two-Way ANOVA**: Compares means across multiple groups based on two factors, accounting for interactions.\n",
        "- **Repeated Measures ANOVA**: Compares means from the same group at different times or under different conditions.\n",
        "\n",
        "### **22) What is the F-test, and how does it relate to hypothesis testing?**\n",
        "The **F-test** compares the variances of two samples to determine if they come from populations with equal variances.\n",
        "- **Relation**: It is used in **ANOVA** and regression analysis to test the equality of variances.\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Below are Python programs for each of the tasks you requested:\n",
        "\n",
        "---\n",
        "\n",
        "### **1) Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data\n",
        "sample_data = np.array([22, 24, 27, 21, 23, 26, 28, 25, 30, 22])\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "population_mean = 25\n",
        "population_std = 2  # Known population standard deviation\n",
        "\n",
        "# Calculate the Z-score\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate the p-value\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "# Output the result\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis\")\n",
        "```\n",
        "\n",
        "### **2) Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python**\n",
        "\n",
        "```python\n",
        "# Simulating data\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(25, 5, 30)  # Mean = 25, std = 5, n = 30\n",
        "\n",
        "# Population parameters\n",
        "population_mean = 25\n",
        "\n",
        "# Perform Z-test\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "population_std = 5  # Known population standard deviation\n",
        "\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "print(f\"Z-score: {z_score}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "```\n",
        "\n",
        "### **3) Implement a one-sample Z-test using Python to compare the sample mean with the population mean**\n",
        "\n",
        "This is very similar to task **1)**. The code provided above for the Z-test works for one-sample Z-tests.\n",
        "\n",
        "### **4) Perform a two-tailed Z-test using Python and visualize the decision region on a plot**\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Z-test calculation\n",
        "sample_data = np.random.normal(25, 5, 30)\n",
        "sample_mean = np.mean(sample_data)\n",
        "population_mean = 25\n",
        "population_std = 5\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "# Plot decision region\n",
        "x = np.linspace(-4, 4, 100)\n",
        "y = stats.norm.pdf(x)\n",
        "plt.plot(x, y)\n",
        "\n",
        "# Plot the critical values for a 0.05 significance level\n",
        "plt.axvline(x=-1.96, color='red', linestyle='--')\n",
        "plt.axvline(x=1.96, color='red', linestyle='--')\n",
        "\n",
        "plt.title(f\"Two-tailed Z-test (Z-score: {z_score:.2f}, P-value: {p_value:.4f})\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### **5) Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing**\n",
        "\n",
        "```python\n",
        "def plot_errors(true_mean, sample_size, population_std, significance_level=0.05):\n",
        "    # Type 1 Error (false positive)\n",
        "    critical_value = stats.norm.ppf(1 - significance_level / 2)\n",
        "    rejection_region = (critical_value, -critical_value)\n",
        "\n",
        "    # Type 2 Error (false negative) - we assume the true mean is different\n",
        "    true_sample_mean = true_mean\n",
        "    z_score = (true_sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Plot\n",
        "    x = np.linspace(-4, 4, 100)\n",
        "    y = stats.norm.pdf(x)\n",
        "\n",
        "    plt.plot(x, y)\n",
        "    plt.axvline(x=-critical_value, color='red', linestyle='--', label=\"Type 1 Error\")\n",
        "    plt.axvline(x=critical_value, color='red', linestyle='--')\n",
        "\n",
        "    plt.fill_between(x, 0, y, where=(x > rejection_region[0]), color='green', alpha=0.3)\n",
        "    plt.fill_between(x, 0, y, where=(x < rejection_region[1]), color='green', alpha=0.3)\n",
        "\n",
        "    plt.title(f\"Type 1 and Type 2 Errors Visualization\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "population_mean = 25\n",
        "sample_size = 30\n",
        "population_std = 5\n",
        "true_mean = 26  # Assume the true mean is different\n",
        "plot_errors(true_mean, sample_size, population_std)\n",
        "```\n",
        "\n",
        "### **6) Write a Python program to perform an independent T-test and interpret the results**\n",
        "\n",
        "```python\n",
        "from scipy.stats import t\n",
        "\n",
        "# Two independent samples\n",
        "sample1 = np.random.normal(25, 5, 30)\n",
        "sample2 = np.random.normal(28, 5, 30)\n",
        "\n",
        "# Perform T-test\n",
        "t_stat, p_value = stats.ttest_ind(sample1, sample2)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: The means are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between the means.\")\n",
        "```\n",
        "\n",
        "### **7) Perform a paired sample T-test using Python and visualize the comparison results**\n",
        "\n",
        "```python\n",
        "# Paired sample data (before and after treatment)\n",
        "before = np.random.normal(25, 5, 30)\n",
        "after = np.random.normal(27, 5, 30)\n",
        "\n",
        "# Perform Paired T-test\n",
        "t_stat, p_value = stats.ttest_rel(before, after)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Visualization\n",
        "plt.boxplot([before, after], labels=['Before', 'After'])\n",
        "plt.title(f\"Paired Sample T-test (P-value: {p_value:.4f})\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### **8) Simulate data and perform both Z-test and T-test, then compare the results using Python**\n",
        "\n",
        "```python\n",
        "# Simulate data\n",
        "sample_data = np.random.normal(25, 5, 30)\n",
        "population_mean = 25\n",
        "population_std = 5\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "# Perform Z-test\n",
        "z_score = (np.mean(sample_data) - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "z_p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "# Perform T-test\n",
        "t_stat, t_p_value = stats.ttest_1samp(sample_data, population_mean)\n",
        "\n",
        "print(f\"Z-test P-value: {z_p_value}\")\n",
        "print(f\"T-test P-value: {t_p_value}\")\n",
        "\n",
        "if z_p_value < 0.05:\n",
        "    print(\"Z-test: Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"Z-test: Fail to reject the null hypothesis.\")\n",
        "\n",
        "if t_p_value < 0.05:\n",
        "    print(\"T-test: Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"T-test: Fail to reject the null hypothesis.\")\n",
        "```\n",
        "\n",
        "### **9) Write a Python function to calculate the confidence interval for a sample mean and explain its significance**\n",
        "\n",
        "```python\n",
        "def confidence_interval(sample_data, confidence_level=0.95):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_std = np.std(sample_data, ddof=1)\n",
        "    sample_size = len(sample_data)\n",
        "\n",
        "    # Calculate the margin of error using the t-distribution\n",
        "    critical_value = stats.t.ppf((1 + confidence_level) / 2, df=sample_size-1)\n",
        "    margin_of_error = critical_value * (sample_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Confidence Interval\n",
        "    ci_lower = sample_mean - margin_of_error\n",
        "    ci_upper = sample_mean + margin_of_error\n",
        "\n",
        "    return (ci_lower, ci_upper)\n",
        "\n",
        "# Example usage\n",
        "sample_data = np.random.normal(25, 5, 30)\n",
        "ci = confidence_interval(sample_data)\n",
        "print(f\"95% Confidence Interval: {ci}\")\n",
        "\n",
        "Below are Python code implementations for the requested tasks:\n",
        "\n",
        "---\n",
        "\n",
        "### **10) Write a Python program to calculate the margin of error for a given confidence level using sample data**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def margin_of_error(sample_data, confidence_level=0.95):\n",
        "    # Calculate sample statistics\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_std = np.std(sample_data, ddof=1)\n",
        "    sample_size = len(sample_data)\n",
        "\n",
        "    # Find the critical value for the confidence level\n",
        "    critical_value = stats.t.ppf((1 + confidence_level) / 2, df=sample_size - 1)\n",
        "\n",
        "    # Calculate margin of error\n",
        "    margin_of_error = critical_value * (sample_std / np.sqrt(sample_size))\n",
        "    return margin_of_error\n",
        "\n",
        "# Example usage\n",
        "sample_data = np.random.normal(50, 10, 100)  # Example data\n",
        "error = margin_of_error(sample_data, 0.95)\n",
        "print(f\"Margin of error: {error}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **11) Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process**\n",
        "\n",
        "```python\n",
        "def bayes_theorem(prior, likelihood, evidence):\n",
        "    \"\"\"\n",
        "    Bayes' Theorem: P(A|B) = (P(B|A) * P(A)) / P(B)\n",
        "    :param prior: P(A), the prior probability\n",
        "    :param likelihood: P(B|A), the likelihood of the evidence given the hypothesis\n",
        "    :param evidence: P(B), the total probability of the evidence\n",
        "    :return: Posterior probability P(A|B)\n",
        "    \"\"\"\n",
        "    posterior = (likelihood * prior) / evidence\n",
        "    return posterior\n",
        "\n",
        "# Example: Disease detection\n",
        "prior = 0.01  # Prior probability of having the disease\n",
        "likelihood = 0.90  # Likelihood of testing positive given you have the disease\n",
        "evidence = 0.05  # Probability of testing positive (with or without disease)\n",
        "\n",
        "posterior = bayes_theorem(prior, likelihood, evidence)\n",
        "print(f\"Posterior probability: {posterior}\")\n",
        "```\n",
        "\n",
        "Explanation: **Bayes' Theorem** updates our belief about an event (A) after observing new evidence (B). The formula combines prior knowledge (prior probability), the likelihood of the observed evidence under the hypothesis, and the total probability of the evidence.\n",
        "\n",
        "---\n",
        "\n",
        "### **12) Perform a Chi-square test for independence between two categorical variables in Python**\n",
        "\n",
        "```python\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "# Example data: Contingency table (Observed counts)\n",
        "data = np.array([[10, 20, 30], [6, 9, 11], [4, 7, 12]])\n",
        "\n",
        "# Perform Chi-square test\n",
        "chi2_stat, p_value, dof, expected = stats.chi2_contingency(data)\n",
        "\n",
        "print(f\"Chi2 statistic: {chi2_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(f\"Expected frequencies:\\n{expected}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant relationship between the variables.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant relationship between the variables.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **13) Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Example observed data\n",
        "observed = np.array([[10, 20], [30, 40]])\n",
        "\n",
        "# Perform Chi-square test to get expected frequencies\n",
        "chi2_stat, p_value, dof, expected = stats.chi2_contingency(observed)\n",
        "\n",
        "print(f\"Observed data:\\n{observed}\")\n",
        "print(f\"Expected frequencies:\\n{expected}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **14) Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Observed data\n",
        "observed = np.array([15, 25, 35, 25])\n",
        "\n",
        "# Expected probabilities for the goodness-of-fit test\n",
        "expected = np.array([25, 25, 25, 25])  # Even distribution\n",
        "\n",
        "# Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = stats.chisquare(observed, expected)\n",
        "\n",
        "print(f\"Chi2 statistic: {chi2_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: The data doesn't fit the expected distribution.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The data fits the expected distribution.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **15) Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate a Chi-square distribution with 2 degrees of freedom\n",
        "data = np.random.chisquare(df=2, size=1000)\n",
        "\n",
        "# Plot the Chi-square distribution\n",
        "plt.hist(data, bins=30, density=True, alpha=0.7, color='g', edgecolor='black')\n",
        "\n",
        "# Plot the theoretical Chi-square distribution\n",
        "x = np.linspace(0, np.max(data), 100)\n",
        "plt.plot(x, stats.chi2.pdf(x, df=2), 'r-', label=\"Theoretical Chi-square PDF\")\n",
        "\n",
        "plt.title('Chi-square Distribution (df=2)')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "Explanation: The Chi-square distribution is often used in hypothesis testing for categorical data. It is right-skewed and the shape depends on the degrees of freedom (df). Higher df make the distribution more symmetric.\n",
        "\n",
        "---\n",
        "\n",
        "### **16) Implement an F-test using Python to compare the variances of two random samples**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate two random samples\n",
        "sample1 = np.random.normal(10, 2, 100)\n",
        "sample2 = np.random.normal(12, 3, 100)\n",
        "\n",
        "# Perform F-test for equality of variances\n",
        "f_stat, p_value = stats.levene(sample1, sample2)\n",
        "\n",
        "print(f\"F-statistic: {f_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in variances.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **17) Write a Python program to perform an ANOVA test to compare means between multiple groups and interpret the results**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate three groups of data\n",
        "group1 = np.random.normal(20, 5, 30)\n",
        "group2 = np.random.normal(25, 5, 30)\n",
        "group3 = np.random.normal(30, 5, 30)\n",
        "\n",
        "# Perform ANOVA test\n",
        "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "print(f\"F-statistic: {f_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: The means of the groups are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The means of the groups are not significantly different.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **18) Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulate three groups of data\n",
        "group1 = np.random.normal(20, 5, 30)\n",
        "group2 = np.random.normal(25, 5, 30)\n",
        "group3 = np.random.normal(30, 5, 30)\n",
        "\n",
        "# Perform one-way ANOVA test\n",
        "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "print(f\"F-statistic: {f_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Plot boxplot\n",
        "plt.boxplot([group1, group2, group3], labels=['Group 1', 'Group 2', 'Group 3'])\n",
        "plt.title(\"One-way ANOVA: Group Comparison\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **19) Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA**\n",
        "\n",
        "```python\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "def check_anova_assumptions(group1, group2, group3):\n",
        "    # Check normality (Shapiro-Wilk test)\n",
        "    for group, name in zip([group1, group2, group3], ['Group 1', 'Group 2', 'Group 3']):\n",
        "        stat, p_value = stats.shapiro(group)\n",
        "        print(f\"Normality test for {name}: Statistic={stat}, P-value={p_value}\")\n",
        "        if p_value < 0.05:\n",
        "            print(f\"{name} is not normally distributed.\")\n",
        "\n",
        "    # Check equal variance (Levene's test)\n",
        "    stat, p_value = stats.levene(group1, group2, group3)\n",
        "    print(f\"Levene's test for equal variance: Statistic={stat}, P-value={p_value}\")\n",
        "    if p_value < 0.05:\n",
        "        print(\"The variances are not equal.\")\n",
        "\n",
        "# Example usage\n",
        "group1 = np.random.normal(20, 5, 30)\n",
        "group2 = np.random.normal(25, 5, 30)\n",
        "group3 = np.random.normal(30, 5, 30)\n",
        "\n",
        "check_anova_assumptions(group1, group2, group3)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **20) Perform a two-way ANOVA test using Python to study the\n",
        "\n",
        " interaction between two factors and visualize the results**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Simulate data for two-way ANOVA\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'Factor1': np.repeat(['A', 'B'], 30),\n",
        "    'Factor2': np.tile(['X', 'Y'], 30),\n",
        "    'Score': np.random.normal(25, 5, 60)\n",
        "})\n",
        "\n",
        "# Perform two-way ANOVA\n",
        "model = smf.ols('Score ~ C(Factor1) + C(Factor2) + C(Factor1):C(Factor2)', data=data).fit()\n",
        "anova_table = sm.stats.anova_lm(model)\n",
        "print(anova_table)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **21) Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Parameters for the F-distribution\n",
        "dfn = 3  # Degrees of freedom numerator\n",
        "dfd = 10  # Degrees of freedom denominator\n",
        "\n",
        "# Generate values for plotting\n",
        "x = np.linspace(0, 5, 1000)\n",
        "y = stats.f.pdf(x, dfn, dfd)\n",
        "\n",
        "# Plot the F-distribution\n",
        "plt.plot(x, y, label=f\"F-distribution (dfn={dfn}, dfd={dfd})\")\n",
        "plt.title(\"F-distribution\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **22) Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means**\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate data for 3 groups\n",
        "group1 = np.random.normal(50, 10, 30)\n",
        "group2 = np.random.normal(55, 10, 30)\n",
        "group3 = np.random.normal(60, 10, 30)\n",
        "\n",
        "# Perform One-way ANOVA\n",
        "f_stat, p_value = stats.f_oneway(group1, group2, group3)\n",
        "\n",
        "print(f\"F-statistic: {f_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Plot boxplot\n",
        "plt.boxplot([group1, group2, group3], labels=[\"Group 1\", \"Group 2\", \"Group 3\"])\n",
        "plt.title(\"One-way ANOVA Comparison\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **23) Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate data\n",
        "data = np.random.normal(25, 5, 100)\n",
        "\n",
        "# Perform one-sample Z-test\n",
        "z_stat = (np.mean(data) - 25) / (5 / np.sqrt(100))\n",
        "z_p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
        "\n",
        "print(f\"Z-statistic: {z_stat}\")\n",
        "print(f\"P-value: {z_p_value}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **24) Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample data\n",
        "data = np.random.normal(25, 5, 100)\n",
        "\n",
        "# Population variance (assumed)\n",
        "population_variance = 25\n",
        "\n",
        "# Calculate sample variance\n",
        "sample_variance = np.var(data, ddof=1)\n",
        "\n",
        "# Perform Chi-square test for variance\n",
        "chi2_stat = (len(data) - 1) * sample_variance / population_variance\n",
        "p_value = 1 - stats.chi2.cdf(chi2_stat, df=len(data)-1)\n",
        "\n",
        "print(f\"Chi2 statistic: {chi2_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: The variance is significantly different from the population variance.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in variance.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **25) Write a Python script to perform a Z-test for comparing proportions between two datasets or groups**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate two sample proportions\n",
        "sample1_successes = 45\n",
        "sample1_size = 100\n",
        "sample2_successes = 40\n",
        "sample2_size = 100\n",
        "\n",
        "# Calculate sample proportions\n",
        "p1 = sample1_successes / sample1_size\n",
        "p2 = sample2_successes / sample2_size\n",
        "\n",
        "# Calculate the pooled proportion\n",
        "pooled_p = (sample1_successes + sample2_successes) / (sample1_size + sample2_size)\n",
        "\n",
        "# Z-test formula for comparing proportions\n",
        "z_stat = (p1 - p2) / np.sqrt(pooled_p * (1 - pooled_p) * (1/sample1_size + 1/sample2_size))\n",
        "\n",
        "# Calculate the p-value\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
        "\n",
        "print(f\"Z-statistic: {z_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: The proportions are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between the proportions.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **26) Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate two random samples\n",
        "sample1 = np.random.normal(25, 5, 30)\n",
        "sample2 = np.random.normal(30, 6, 30)\n",
        "\n",
        "# F-test for equality of variances\n",
        "f_stat = np.var(sample1, ddof=1) / np.var(sample2, ddof=1)\n",
        "dfn = len(sample1) - 1  # Degrees of freedom for sample 1\n",
        "dfd = len(sample2) - 1  # Degrees of freedom for sample 2\n",
        "\n",
        "# Calculate the p-value for the F-statistic\n",
        "p_value = 1 - stats.f.cdf(f_stat, dfn, dfd)\n",
        "\n",
        "print(f\"F-statistic: {f_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in variances.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **27) Perform a Chi-square test for goodness of fit with simulated data and analyze the results**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Simulate observed data\n",
        "observed = np.random.choice([10, 20, 30, 40], 100, p=[0.25, 0.25, 0.25, 0.25])\n",
        "\n",
        "# Expected frequencies (assumed)\n",
        "expected = np.array([25, 25, 25, 25])\n",
        "\n",
        "# Perform Chi-square test for goodness of fit\n",
        "chi2_stat, p_value = stats.chisquare(np.bincount(observed), expected)\n",
        "\n",
        "print(f\"Chi2 statistic: {chi2_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: The observed data does not fit the expected distribution.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The observed data fits the expected distribution.\")\n",
        "```\n"
      ],
      "metadata": {
        "id": "QyVt8bY2hVCx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}